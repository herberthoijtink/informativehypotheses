[["index.html", "Informative Hypotheses Chapter 1 Introduction", " Informative Hypotheses Herbert Hoijtink, Nikola Sekulovski 2021-10-21 Chapter 1 Introduction This is a template GitBook based on A GitBook Example for Teaching and bookdown: Authoring Books and Technical Documents with R Markdown. "],["monte-carlo-simulations.html", "Chapter 2 Monte Carlo Simulations 2.1 The Confidence Interval 2.2 The Central Limit Theorem", " Chapter 2 Monte Carlo Simulations library(tidyverse) # {-} no chapter number # see Appendix.Rmd how to make parts in a book # don&#39;t forget library(bookdown) # R - help -cheatsheets 2.1 The Confidence Interval In this exercise I will try to repeat the example given by Gerko Vink The main idea of this exercise is to illustrate the nature of the Confidence Interval as described by Neyman (1934) We set a seed to make our results reproducible: set.seed(6465) The first step is to take 100 samples (in this case of size 800) from a normal distributuon with \\(\\mu = 0\\) and \\(\\sigma = 1\\): samples &lt;-plyr::rlply(100, rnorm(800, 0, 1)) Secondly, we need to calculate for the mean of each sample: the absolute bias; standard error lower bound of the 95% confidence interval and upper bound of the 95% confidence interval. We can construct a function that does this: samp_function &lt;- function(x) { m &lt;- mean(x) n &lt;- length(x) se &lt;- 1/sqrt(n) bias &lt;- abs(-0 - m) df &lt;- n - 1 interval &lt;- qt(.975, df) * se return(c(m, bias, se, m - interval, m + interval)) } format &lt;- c(&quot;Mean&quot; = 0, &quot;Bias&quot; = 0, &quot;Std.Err&quot; = 0, &quot;Lower&quot; = 0, &quot;Upper&quot; = 0) Now we use the constructed function samp_function on all 100 samples contained in the object samples. And we also add a new column to the results that indicates which CI of the respective samples does contain \\(\\mu\\). results &lt;- samples %&gt;% vapply(., samp_function, format) %&gt;% t %&gt;% as_tibble %&gt;% mutate(Covered = ifelse(Lower &lt; 0 &amp; Upper &gt; 0, 1, 0)) We can also add a table with the sample statistics of the samples whose CIs do not contain \\(\\mu\\). # the results contains the table content that is piped into the table results %&gt;% filter(Covered ==0) %&gt;% kableExtra::kable(caption = &quot;Here is a table of the samples&quot; ) Table 2.1: Here is a table of the samples Mean Bias Std.Err Lower Upper Covered -0.0945589 0.0945589 0.0353553 -0.1639592 -0.0251585 0 0.0740058 0.0740058 0.0353553 0.0046055 0.1434062 0 And finally we can also make a nice plot illustrating everything that we did so far. # in the line above also the size of the figure can be adjusted lims &lt;- aes(ymax = results$Upper, ymin = results$Lower) ggplot(results, aes(y=Mean, x=1:100, colour = Covered)) + geom_hline(aes(yintercept = 0)) + geom_pointrange(lims) + xlab(&quot;Simulations&quot;) + ylab(&quot;Means and 95% Confidence Intervals&quot;) ## Warning: Use of `results$Upper` is discouraged. Use `Upper` instead. ## Warning: Use of `results$Lower` is discouraged. Use `Lower` instead. Figure 2.1: Here is a plot of the CIs In this case only two out of 100 CIs do not include the true population mean. 2.2 The Central Limit Theorem Here we will also try to illustrate the Central Limit Theorem, in its most basic form, with a very simple example. First we draw 1000 samples (again of size 800), form , say, a Poisson distribution, of course we couldve drawn them from a uniform or an exponential as well. Now we calculate the mean for each sample: means &lt;- samples_2 %&gt;% lapply(., mean) %&gt;% as.data.frame() %&gt;% t() And now we plot a histogram of the resulting means: hist(t(means)) Figure 2.2: Histogram of the sampling distribution of the mean "],["informative-hypothesis-bayesian-testing-for-multi-level-models.html", "Chapter 3 Informative hypothesis (Bayesian) testing for multi-level models 3.1 Example for citation", " Chapter 3 Informative hypothesis (Bayesian) testing for multi-level models 3.1 Example for citation We will be using the Approximate Adjusted Fractional Bayes factor proposed by Gu, Mulder, &amp; Hoijtink (2018), which is implemented in the R package bain (Gu, Hoijtink, Mulder, &amp; van Lissa, 2021). We can reference like this Hoijtink, Klugkist, &amp; Boelen (2008) or like this (Hoijtink et al., 2008) "],["literature.html", "Literature", " Literature Gu, X., Hoijtink, H., Mulder, J., &amp; van Lissa, C. J. (2021). Bain: Bayes factors for informative hypotheses. Retrieved from https://CRAN.R-project.org/package=bain Gu, X., Mulder, J., &amp; Hoijtink, H. (2018). Approximated adjusted fractional bayes factors: A general method for testing informative hypotheses. British Journal of Mathematical and Statistical Psychology, 71, 229261. Hoijtink, H., Klugkist, I., &amp; Boelen, P. A. (2008). Bayesian evaluation of informative hypotheses. Springer. "],["appendix-a.html", "Appendix A", " Appendix A "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
